# Image Recognition
## Survey
1. [Attention Mechanisms in Computer Vision: A Survey](https://arxiv.org/abs/2111.07624) (2021)

## Convolution
1. [An Attention Module for Convolutional Neural Networks](https://arxiv.org/abs/2108.08205) (2021)
2. [Unifying Nonlocal Blocks for Neural Networks](https://arxiv.org/abs/2108.02451) (ICCV 2021)
3. [PP-LCNet: A Lightweight CPU Convolutional Neural Network](https://arxiv.org/abs/2109.15099) (2021)
4. [Network Augmentation for Tiny Deep Learning](https://arxiv.org/abs/2110.08890) (2021)
5. [Recurrence along Depth: Deep Convolutional Neural Networks with Recurrent Layer Aggregation](https://arxiv.org/abs/2110.11852) (NeurIPS 2021)
6. [Dynamic Region-Aware Convolution](https://arxiv.org/abs/2003.12243) (CVPR 2021)
7. [Non-deep Networks](https://arxiv.org/abs/2110.07641) (2021)
8. [Can Vision Transformers Perform Convolution?](https://arxiv.org/abs/2111.01353) (2021)
9. [On the Integration of Self-Attention and Convolution](https://arxiv.org/abs/2111.14556) (2021)
10. [NAM: Normalization-based Attention Module](https://arxiv.org/abs/2111.12419) (2021)
11. [Augmenting Convolutional networks with attention-based aggregation](https://arxiv.org/abs/2112.13692) (2021)
12. [Rethinking Nearest Neighbors for Visual Classification](https://arxiv.org/abs/2112.08459) (2021)
13. [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) (2022)
14. [Omni-Dimensional Dynamic Convolution](https://openreview.net/forum?id=DmpCfq6Mg39) (ICLR 2022)
15. [You Only Cut Once: Boosting Data Augmentation with a Single Cut](https://arxiv.org/abs/2201.12078) (2022)
16. [Revisiting Dynamic Convolution via Matrix Decomposition](https://arxiv.org/abs/2103.08756) (ICLR 2021)

## Transformer
1. [PSViT: Better Vision Transformer via Token Pooling and Attention Sharing](https://arxiv.org/abs/2108.03428) (2021)
2. [Rethinking Spatial Dimensions of Vision Transformers](https://arxiv.org/abs/2103.16302) (2021)
3. [Conformer: Local Features Coupling Global Representations for Visual Recognition](https://arxiv.org/abs/2105.03889) (2021)
4. [Co-Scale Conv-Attentional Image Transformers](https://arxiv.org/abs/2104.06399) (2021)
5. [Mobile-Former: Bridging MobileNet and Transformer](https://arxiv.org/abs/2108.05895) (2021)
6. [Scalable Visual Transformers with Hierarchical Pooling](https://arxiv.org/abs/2103.10619) (2021)
7. [Exploring and Improving Mobile Level Vision Transformers](https://arxiv.org/abs/2108.13015) (2021)
8. [CMT: Convolutional Neural Networks Meet Vision Transformers](https://arxiv.org/abs/2107.06263) (2021)
9. [CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention](https://arxiv.org/abs/2108.00154) (2021)
10. [Global Filter Networks for Image Classification](https://arxiv.org/abs/2107.00645) (2021)
11. [Focal Self-attention for Local-Global Interactions in Vision Transformers](https://arxiv.org/abs/2107.00641) (2021)
12. [Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length](https://arxiv.org/abs/2105.15075) (2021)
13. [Bottleneck Transformers for Visual Recognition](https://arxiv.org/abs/2101.11605) (2021)
14. [Efficient Training of Visual Transformers with Small-Size Datasets](https://arxiv.org/abs/2106.03746) (2021)
15. [CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification](https://arxiv.org/abs/2103.14899) (ICCV 2021)
16. [Fastformer: Additive Attention Can Be All You Need](https://arxiv.org/abs/2108.09084) (2021)
17. [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) (2021)
18. [Patches Are All You Need?](https://openreview.net/forum?id=TVHS5Y4dNvM) (ICLR 2022)
19. [Blending Anti-Aliasing into Vision Transformer](https://arxiv.org/abs/2110.15156) (NeurIPS 2021)
20. [Glance-and-Gaze Vision Transformer](https://arxiv.org/abs/2106.02277) (2021)
21. [Dynamic Grained Encoder for Vision Transformers](https://openreview.net/forum?id=gnAIV-EKw2) (NeurIPS 2021)
22. [All Tokens Matter: Token Labeling for Training Better Vision Transformers](https://arxiv.org/abs/2104.10858) (2021)
23. [Early Convolutions Help Transformers See Better](https://arxiv.org/abs/2106.14881) (NeurIPS 2021)
24. [TransMix: Attend to Mix for Vision Transformers](https://arxiv.org/abs/2111.09833) (2021)
25. [Self-slimmed Vision Transformer](https://arxiv.org/abs/2111.12624) (2021)
26. [PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers](https://arxiv.org/abs/2111.12710) (2021)
27. [Florence: A New Foundation Model for Computer Vision](https://arxiv.org/abs/2111.11432) (2021)
28. [MPViT: Multi-Path Vision Transformer for Dense Prediction](https://arxiv.org/abs/2112.11010) (2021)
29. [AdaViT: Adaptive Vision Transformers for Efficient Image Recognition](https://arxiv.org/abs/2111.15668) (2021)
30. [ATS: Adaptive Token Sampling For Efficient Vision Transformers](https://arxiv.org/abs/2111.15667) (2021)
31. [Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer](https://arxiv.org/abs/2108.01390) (2021)
32. [Improved Multiscale Vision Transformers for Classification and Detection](https://arxiv.org/abs/2112.01526) (2021)
33. [TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?](https://arxiv.org/abs/2106.11297) (NeurIPS 2021)
34. [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) (2021)
35. [ELSA: Enhanced Local Self-Attention for Vision Transformer](https://arxiv.org/abs/2112.12786) (2021)
36. [Lite Vision Transformer with Enhanced Self-Attention](https://arxiv.org/abs/2112.10809) (2021)
37. [SimViT: Exploring a Simple Vision Transformer with sliding windows](https://arxiv.org/abs/2112.13085) (2021)
38. [Pale Transformer: A General Vision Transformer Backbone with Pale-Shaped Attention](https://arxiv.org/abs/2112.14000) (2021)
39. [PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture](https://arxiv.org/abs/2201.00978) (2021)
40. [Vision Transformer with Deformable Attention](https://arxiv.org/abs/2201.00520) (2021)
41. [QuadTree Attention for Vision Transformers](https://arxiv.org/abs/2201.02767) (2022)
42. [Aggregating Global Features into Local Vision Transformer](https://arxiv.org/abs/2201.12903) (2022)
43. [Training Vision Transformers with Only 2040 Images](https://arxiv.org/abs/2201.10728) (2022)

## MLP
1. [AS-MLP: An Axial Shifted MLP Architecture for Vision](https://arxiv.org/abs/2107.08391) (2021)
2. [RaftMLP: Do MLP-based Models Dream of Winning Over Computer Vision?](https://arxiv.org/abs/2108.04384) (2021)
3. [Hire-MLP: Vision MLP via Hierarchical Rearrangement](https://arxiv.org/abs/2108.13341) (2021)
4. [Sparse-MLP: A Fully-MLP Architecture with Conditional Computation](https://arxiv.org/abs/2109.02008) (2021)
5. [Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?](https://arxiv.org/abs/2109.05422) (2021)
6. [ConvMLP: Hierarchical Convolutional MLPs for Vision](https://arxiv.org/abs/2109.04454) (2021)
7. [Container: Context Aggregation Network](https://arxiv.org/abs/2106.01401) (NeuIPS 2021)
8. [An Image Patch is a Wave: Phase-Aware Vision MLP](https://arxiv.org/abs/2111.12294) (2021)
9. [MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) (2021)
10. [CycleMLP: A MLP-like Architecture for Dense Prediction](https://arxiv.org/abs/2107.10224) (2022)
11. [AS-MLP: An Axial Shifted MLP Architecture for Vision](https://arxiv.org/abs/2107.08391) (2022)

## Self-Supervised Vision Transformer
1. [An Empirical Study of Training Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.02057) (2021)
2. [Revitalizing CNN Attentions via Transformers in Self-Supervised Visual Representation Learning](https://arxiv.org/abs/2110.05340) (NeurIPS 2021)

## Neural Architecture Search
1. [Searching for Efficient Multi-Stage Vision Transformers](https://arxiv.org/abs/2109.00642v1) (2021)

## Others
1. [Tune It or Donâ€™t Use It: Benchmarking Data-Efficient Image Classification](https://arxiv.org/abs/2108.13122) (ICCV 2021)
2. [A Battle of Network Structures: An Empirical Study of CNN, Transformer, and MLP](https://arxiv.org/abs/2108.13002) (2021)
3. [Towards Learning Spatially Discriminative Feature Representations](https://arxiv.org/abs/2109.01359) (ICCV 2021)
4. 

## Visual Feature Attribution
1. [Keep CALM and Improve Visual Feature Attribution](https://arxiv.org/abs/2106.07861) (ICCV 2021)
2. 

## Fine-grained Visual Recognition
1. [A free lunch from ViT: Adaptive Attention Multi-scale Fusion Transformer for Fine-grained Visual Recognition](https://arxiv.org/abs/2110.01240) (2021)

## Self-supervised
1. [SiT: Self-supervised vIsion Transformer](https://arxiv.org/abs/2104.03602) (2021)

## Small Datasets
1. [Efficient Training of Visual Transformers with Small Datasets](https://arxiv.org/abs/2106.03746) (2021)


