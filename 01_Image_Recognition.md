# Image Recognition
## Convolution
1. [An Attention Module for Convolutional Neural Networks](https://arxiv.org/abs/2108.08205) (2021)
2. [Unifying Nonlocal Blocks for Neural Networks](https://arxiv.org/abs/2108.02451) (ICCV 2021)
3. [PP-LCNet: A Lightweight CPU Convolutional Neural Network](https://arxiv.org/abs/2109.15099) (2021)
4. [Network Augmentation for Tiny Deep Learning](https://arxiv.org/abs/2110.08890) (2021)

## Transformer
1. [PSViT: Better Vision Transformer via Token Pooling and Attention Sharing](https://arxiv.org/abs/2108.03428) (2021)
2. [Rethinking Spatial Dimensions of Vision Transformers](https://arxiv.org/abs/2103.16302) (2021)
3. [Conformer: Local Features Coupling Global Representations for Visual Recognition](https://arxiv.org/abs/2105.03889) (2021)
4. [Co-Scale Conv-Attentional Image Transformers](https://arxiv.org/abs/2104.06399) (2021)
5. [Mobile-Former: Bridging MobileNet and Transformer](https://arxiv.org/abs/2108.05895) (2021)
6. [Scalable Visual Transformers with Hierarchical Pooling](https://arxiv.org/abs/2103.10619) (2021)
7. [Exploring and Improving Mobile Level Vision Transformers](https://arxiv.org/abs/2108.13015) (2021)
8. [CMT: Convolutional Neural Networks Meet Vision Transformers](https://arxiv.org/abs/2107.06263) (2021)
9. [CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention](https://arxiv.org/abs/2108.00154) (2021)
10. [Global Filter Networks for Image Classification](https://arxiv.org/abs/2107.00645) (2021)
11. [Focal Self-attention for Local-Global Interactions in Vision Transformers](https://arxiv.org/abs/2107.00641) (2021)
12. [Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length](https://arxiv.org/abs/2105.15075) (2021)
13. [Bottleneck Transformers for Visual Recognition](https://arxiv.org/abs/2101.11605) (2021)
14. [Efficient Training of Visual Transformers with Small-Size Datasets](https://arxiv.org/abs/2106.03746) (2021)
15. [CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification](https://arxiv.org/abs/2103.14899) (ICCV 2021)
16. [Fastformer: Additive Attention Can Be All You Need](https://arxiv.org/abs/2108.09084) (2021)
17. [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) (2021)

## MLP
1. [AS-MLP: An Axial Shifted MLP Architecture for Vision](https://arxiv.org/abs/2107.08391) (2021)
2. [RaftMLP: Do MLP-based Models Dream of Winning Over Computer Vision?](https://arxiv.org/abs/2108.04384) (2021)
3. [Hire-MLP: Vision MLP via Hierarchical Rearrangement](https://arxiv.org/abs/2108.13341) (2021)
4. [Sparse-MLP: A Fully-MLP Architecture with Conditional Computation](https://arxiv.org/abs/2109.02008) (2021)
5. [Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?](https://arxiv.org/abs/2109.05422) (2021)
6. [ConvMLP: Hierarchical Convolutional MLPs for Vision](https://arxiv.org/abs/2109.04454) (2021)

## Self-Supervised Vision Transformer
1. [An Empirical Study of Training Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.02057) (2021)
2. 

## Neural Architecture Search
1. [Searching for Efficient Multi-Stage Vision Transformers](https://arxiv.org/abs/2109.00642v1) (2021)

## Others
1. [Tune It or Donâ€™t Use It: Benchmarking Data-Efficient Image Classification](https://arxiv.org/abs/2108.13122) (ICCV 2021)
2. [A Battle of Network Structures: An Empirical Study of CNN, Transformer, and MLP](https://arxiv.org/abs/2108.13002) (2021)
3. [Towards Learning Spatially Discriminative Feature Representations](https://arxiv.org/abs/2109.01359) (ICCV 2021)
4. 

## Visual Feature Attribution
1. [Keep CALM and Improve Visual Feature Attribution](https://arxiv.org/abs/2106.07861) (ICCV 2021)
2. 

## Fine-grained Visual Recognition
1. [A free lunch from ViT: Adaptive Attention Multi-scale Fusion Transformer for Fine-grained Visual Recognition](https://arxiv.org/abs/2110.01240) (2021)



